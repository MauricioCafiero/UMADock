{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivBeJvE3UpP2"
   },
   "source": [
    "# UMADock With Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdPl0WLkUrOB"
   },
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOBVx1AyUsu6",
    "outputId": "ed45c8c3-e9f3-470b-8d47-8bf067594151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet  langchain-huggingface\n",
    "!pip install langchain_core --quiet\n",
    "! pip -q install langchain_community\n",
    "!pip install -q langgraph\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xOVvX3KHUsqr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import SystemMessage, trim_messages, AIMessage, HumanMessage, ToolCall\n",
    "\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "from gradio_client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450,
     "referenced_widgets": [
      "6dd4229e7f2c491481314978fd6b3ceb",
      "c0dabe5f43744828a2bc93d1f87ce87e",
      "dc92f23cd3c5442f99eed4461a3558b8",
      "cf75d044303440a481587d326b541766",
      "25c13de1ad0c40cd8ef07e038950201c",
      "6ca7c82f260e467e9a1ef08cdfbc2734",
      "6b151d29e4a948e29c7e3668d2bfc402",
      "1ed686856e4b4dea9052fb28256119fd",
      "e7124c31945b4cb8b06fec081bd9f63d",
      "c015912dbfe644218a834e3716c88d6b",
      "77792e03b66d43cea43eeb109ebea08a",
      "a116fafe9348456f95d9b0bda8ebf4a4",
      "59a62a29fe404d33bb2ea27442554cc9",
      "9178c731053343959982ca5777960938",
      "5215f385c62849dfa8b66bc31bfa62bc",
      "e6e8fc07a8e242ba82bbd26b2dd98302",
      "c6b0cf9f3956491d98d49bef44d835a7",
      "e2113bddc444459da7eb17f0f6b338e3",
      "bd6f95aec7984bce85428e5015936582",
      "81fe9ca50c954f93ac9521c1ca84d07a",
      "a34435bd1d1440ff843e435e482c668d",
      "45b0472c7297415a8d1785a67d983364",
      "0e66f919295d472cb0259e7f262a7fc9",
      "35f12b3a49284c5e830910418f640900",
      "6aaa2486eea4496e97ad35d2d2f928f5",
      "75ce134926b1483f8b30cbe8ebf12458",
      "042703c00ef343ab8f37b1ac4e599aee",
      "c0b3b9d37c144e0396880408e25ce006",
      "a576466cb28940c9bf469b6e0d4854f3",
      "8d0d645dc83343d5b9d6a0c2d6f3b17e",
      "bfd8baae607245ccb4669a071fd6d7f4",
      "05e328426cce45f4ba3ebde7e8e4f736",
      "cfa3b0a72b7946c1907d59d6665441e8",
      "5eec18766d204cc6a2c44c21a9631de9",
      "114f1078783840d6a6e71a0689978eea",
      "f01bc1ff466d4cf5892e4e25dce5cd2a",
      "c94d515efd5b4d3bb9af2e8de1f40239",
      "78d1ce42bc6e4ecbbfdab27e6def5430",
      "082cad11fe4443edb5a0063473bd0edd",
      "62e471510d314830b61389ceebcb9a47",
      "de74e26d19e64e8eb5993f0b94907abc",
      "c44fc413020c4bbd85913301409d2705",
      "d61104c464654baeba8c5c1f8288d173",
      "81ebee02f1944b5e8db8783ba27a041c",
      "d8a06c54541e46e59161cd9a7f4d98a3",
      "9f3375414642431395391762da15835d",
      "e6658fec39184b4bb7ff3d41f6fedba0",
      "6308b6f0e55f484a9bfa19a239c9b9e9",
      "40ef0bee3e3d4ce3b0f78e14f3a921b1",
      "3f7a590464cc4e16bd2d5fd6976c7a7c",
      "40c9bfab7d2f492c8243d084a44aacdc",
      "982087702ff34e149d752238cf06a145",
      "24e0f5a6b64943f2a0decd2dd82ccbaf",
      "deb6570bf0f146a8bdb51f7ca74a931d",
      "e6fa48b6e2c04489940240b8bd4c3dea",
      "6218d4f58d8b42ee99da9b5685e75e6a",
      "74f69dc88848453fb91cb0e5ddb094f1",
      "d165538de28540a5b604ee9a514f909a",
      "9567395366a84722b73c494f4ca6ddff",
      "cb8a5c41164044008573b82df588ef64",
      "5cc012c0239e438cb9a5f267f2a14a41",
      "137f6236bbfc4e6590359c97c5050d9c",
      "2c28bab53ec447ed8ad51f734377fd7e",
      "a9fb0cfcb52647648c5d9f63bd251b96",
      "b829a89bff5644bdaf4d81d21d270100",
      "9a1111ea25c74192ae3867a2c203a85a",
      "092ddcf907b64ddb9ed2a2822591af7a",
      "37d8f1d5be5b41b282286b5ca636b33f",
      "7fb2ed9ca1e44cf19391afeb89e97dd3",
      "c23f3c83c4144c3ba636266198bdb244",
      "bea3bb58fc4c4076879a6d75a52ec1d1",
      "e08dc2deed364987acdce03ec46d3824",
      "6f90ae93ae46481899beec823dd213a8",
      "1819d71aa6144c3ea72c07c396568f8c",
      "2e9f78458b6045b38740d3a9a82e46a0",
      "f7ddf3ed614445eb989e6969b969c9d8",
      "e4c7296d26214cb6a9af8b640355e03b",
      "1384819f8daa4672baf2df4ab2a00aaf",
      "d01db70092964dafbb97dffeb82b0b59",
      "e0d9fe0cd7d1457f89b1887a0a92f503",
      "e0c2abdf0e3d40a0aaebb67ee61a9558",
      "f432d6c4c208417eba74903e4d48a35c",
      "8172913f073e4d02a39956443619ba47",
      "090b26fbe24b42ac959fd96a52643318",
      "434f4910603c4100bc2371592ce89c06",
      "b5b5e0a6cae04ca89a2c4f0a7db5fce6",
      "c9e61030baa943e4af2ab5e32722ec5b",
      "3945279ea8f641dd99240335a16ddf86",
      "e72f2b4a50274fb1b3789303ace76405",
      "b097dd01588541e4af29c3973a9b73de",
      "1cf6df37623e4c3099fba3eae635d32c",
      "5c994f55069f40489d1b0a5c99eb08e9",
      "d8dfbff98750453997f97d4bece243fd",
      "9f767915c11c4e16aba9c019adad314b",
      "4098bfa645154836a0dd11a51e005887",
      "e9e7fba2594441a2aee8484d1021b7b5",
      "c64b4629ea1947a8a41bbf97ada2ee57",
      "9116a98025d141b28bbb96640cf6f87b",
      "8c40907e858741108a8ee8cd0ee4ee18",
      "077bd782a7334e7bbeb3d1b282c9aace",
      "92196c249b734837b579129f3d9ab8a0",
      "65fed00628404e6fbab6ad5dea7816fb",
      "3ab9df9280e840f0b1ea902b63e03dfc",
      "34d6f486479d4bf0a30e201b5e0df481",
      "24182ee8e2dc4e7ea7a7f608cef66031",
      "fca5019508e2490a84ecf5233588a458",
      "8b7be71153b94bd6acff0802952be476",
      "a28ca5e6bff54c24b1e4591783094723",
      "e4938a6a6f894f83bcac28fecdc3b847",
      "a9e41cd5832d47f6ae0d923f61f9b478",
      "844a4def1a644f5099d48fbfb005e7e6",
      "09a94705d8454a3598fbf81594ffc0d7",
      "5ae983ca0ffb4e3385be3813f40753af",
      "dd062ca37062410ca414a0d511cd0fd1",
      "cab7f6c9cf0e46afb3383c6346f8d4a1",
      "f1359faf19704963be9de4fd55ee36e9",
      "182fb02c84d44fb9981f85439aee7308",
      "bf16a5b2663e4a02b153e58d1ef6ff0a",
      "2d60a056fba9478db98366117e4a2bf9",
      "3c3ca6edfa504c6db07e61f2fac90b61",
      "493f5d40e3fa4e45895499d6621ba137",
      "d8ffc84c01684142aa74b8ece0ffbda7",
      "48311b1d11f843958e54865209de930e",
      "405a16ef2c7d410fac282d5d149af77e",
      "eeed6df7ddaf444597622f455c295e5e",
      "9790b6b3d10c42a6875683da9a718068",
      "1808b166fc7344efaee412ed1c09c6e5",
      "48beb1a90843407ab9b99fe9ca4a6a0b",
      "3686c1ae39864ac4b845981693b63e38",
      "d16c65ad1ad745289aba68e97825eb37",
      "3d938642c00347848dccaf9aa13f5183",
      "fc2ef8cc4fc140e6b362147e1ad7625d",
      "163be58f94074130a1c614e2b2b62496",
      "88d25bed71f4402f841da31740a025d1",
      "2e3044f6455745c190c84685fc8254bc",
      "02960fab041e4d9498c8270f8e6500b3",
      "fe293fa2baa2420d88dc256519cdb443",
      "5801a2a127d94d5dbe9ce1b30da44d65",
      "873e2ed9af914bba81bc84bd33fc8be9",
      "4b80a03bf7574e68b9a5975f28a289e9",
      "a3b8b6a79ab4484fb7a0749076645f8e",
      "4bde29f038ab484eb1434dd6737f50c4",
      "eb4c38830476412c9939c8164c9700c3"
     ]
    },
    "id": "r5Co3cxvUsmr",
    "outputId": "85de2158-6599-484f-856a-eb8e1be4d800"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd4229e7f2c491481314978fd6b3ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a116fafe9348456f95d9b0bda8ebf4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e66f919295d472cb0259e7f262a7fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eec18766d204cc6a2c44c21a9631de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/15.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a06c54541e46e59161cd9a7f4d98a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/249 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6218d4f58d8b42ee99da9b5685e75e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092ddcf907b64ddb9ed2a2822591af7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1384819f8daa4672baf2df4ab2a00aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72f2b4a50274fb1b3789303ace76405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077bd782a7334e7bbeb3d1b282c9aace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844a4def1a644f5099d48fbfb005e7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ffc84c01684142aa74b8ece0ffbda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163be58f94074130a1c614e2b2b62496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    #model_id= \"swiss-ai/Apertus-8B-Instruct-2509\",\n",
    "    model_id= \"microsoft/Phi-4-mini-instruct\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs = {\"max_new_tokens\": 500, \"temperature\": 0.4})\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qj9RlMDQXkh_"
   },
   "source": [
    "## Define Agent\n",
    "- replace URL in client with gradio link (see UMADock with Gradio notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awfseycLdsot",
    "outputId": "4c21027f-6575-459a-ae0e-dead6284d47a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://132075be3162a9a635.gradio.live/ ✔\n"
     ]
    }
   ],
   "source": [
    "client = Client('https://132075be3162a9a635.gradio.live')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "If6f7Os2zfc_"
   },
   "outputs": [],
   "source": [
    "test = client.predict(query_smiles, query_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ly3VPrfZSzH-"
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "  '''\n",
    "    The state of the agent.\n",
    "  '''\n",
    "  messages: Annotated[list, add_messages]\n",
    "  query_smiles: str\n",
    "  query_protein: str\n",
    "  props_string: str\n",
    "\n",
    "def first_node(state: State) -> State:\n",
    "  '''\n",
    "    The first node of the agent. This node receives the input and asks the LLM\n",
    "    to determine which is the best tool to use to answer the QUERY TASK.\n",
    "\n",
    "      Input: the initial prompt from the user. should contain only one of more of the following:\n",
    "\n",
    "             smiles: the smiles string, protein: the target protein\n",
    "\n",
    "             the value should be separated from the name by a ':' and each field should\n",
    "             be separated from the previous one by a ','.\n",
    "\n",
    "             All of these values are saved to the state\n",
    "\n",
    "      Output: the tool choice\n",
    "  '''\n",
    "  query_smiles = None\n",
    "  query_protein = None\n",
    "  props_string = \"\"\n",
    "  state[\"props_string\"] = props_string\n",
    "\n",
    "  raw_input = state[\"messages\"][-1].content\n",
    "  parts = raw_input.split(',')\n",
    "  for part in parts:\n",
    "    if 'smiles' in part:\n",
    "      query_smiles = part.split(':')[1]\n",
    "      state[\"query_smiles\"] = query_smiles\n",
    "    if 'protein' in part:\n",
    "      query_protein = part.split(':')[1]\n",
    "      state[\"query_protein\"] = query_protein\n",
    "\n",
    "  print(f\"query_smiles: {query_smiles}\")\n",
    "  print(f\"query_protein: {query_protein}\")\n",
    "\n",
    "  props_string += client.predict(query_smiles, query_protein)\n",
    "  state[\"props_string\"] = props_string\n",
    "\n",
    "  return state\n",
    "\n",
    "def parser_node(state: State) -> State:\n",
    "  '''\n",
    "    This is the third node in the agent. It receives the output from the tool,\n",
    "    puts it into a prompt as CONTEXT, and asks the LLM to answer the original\n",
    "    query.\n",
    "\n",
    "      Input: the output from the tool.\n",
    "      Output: the answer to the original query.\n",
    "  '''\n",
    "  props_string = state[\"props_string\"]\n",
    "  query_smiles = state[\"query_smiles\"]\n",
    "  query_protein = state[\"query_protein\"]\n",
    "\n",
    "  prompt = f'Using the CONTEXT below, discuss the results from the docking calculation, \\\n",
    "Wwhere the molecule represented by the SMILES string was docked in the PROTEIN. \\n \\\n",
    "SMILES: {query_smiles}.\\n \\\n",
    "PROTEIN: {query_protein}.\\n \\\n",
    "CONTEXT: {props_string}.\\n '\n",
    "\n",
    "  res = chat_model.invoke(prompt)\n",
    "  return {\"messages\": res}\n",
    "\n",
    "def pretty_print(answer):\n",
    "  final = str(answer['messages'][-1]).split('<|assistant|>')[-1].split('#')[0].strip(\"n\").strip('\\\\').strip('n').strip('\\\\')\n",
    "  for i in range(0,len(final),100):\n",
    "    print(final[i:i+100])\n",
    "\n",
    "def print_short(answer):\n",
    "  for i in range(0,len(answer),100):\n",
    "    print(answer[i:i+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "klnAXIEmd-os"
   },
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "builder.add_node(\"first_node\", first_node)\n",
    "builder.add_node(\"parser_node\", parser_node)\n",
    "\n",
    "builder.add_edge(START, \"first_node\")\n",
    "builder.add_edge(\"first_node\", \"parser_node\")\n",
    "\n",
    "builder.add_edge(\"parser_node\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnEmnOT3umvf"
   },
   "source": [
    "## Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "4CYFr3K9eHEz"
   },
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"messages\": [\n",
    "        HumanMessage('smiles: c1ccc(F)cc1, protein:DRD2')\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLKT1_OegN4R",
    "outputId": "b1fa6ef3-7e6a-4c7f-8f3b-8038ade1946b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_smiles:  c1ccc(F)cc1\n",
      "query_protein: DRD2\n",
      "The docking calculation results indicate that the molecule represented by the SMILES string \"c1ccc(F\n",
      ")cc1\" (which is 1-fluoro-2,5-dimethylbenzene) has been docked into the DRD2 protein. The lowest elec\n",
      "tronic binding energy observed was from conformer 1, with a binding energy of -13.520 kcal/mol. This\n",
      " suggests that in pose 1, the 1-fluoro-2,5-dimethylbenzene molecule interacts with the DRD2 protein \n",
      "in a manner that results in a stable and energetically favorable binding configuration. The negative\n",
      " value of the binding energy indicates that the interaction is exothermic, meaning that the binding \n",
      "of the molecule to the protein releases energy, which is a favorable outcome in drug design and mole\n",
      "cular docking studies. The specific details of the interaction, such as the binding site on the DRD2\n",
      " protein and the nature of the interactions (e.g., hydrogen bonds, hydrophobic interactions, etc.), \n",
      "would provide further insights into the potential efficacy and mechanism of action of this molecule \n",
      "in relation to the DRD2 protein.' additional_kwargs={} response_metadata={} id='run--e1cee82f-2ebf-4\n",
      "e9a-8d67-0eed24306eaf-0'\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "cs = []\n",
    "for c in graph.stream(input): #, stream_mode='updates'):\n",
    "  m = re.findall(r'[a-z]+\\_node', str(c))\n",
    "  if len(m) != 0:\n",
    "    reply = c[str(m[0])]['messages']\n",
    "    if 'assistant' in str(reply):\n",
    "      reply = str(reply).split(\"<|assistant|>\")[-1].split('#')[0].strip()\n",
    "      print_short(reply)\n",
    "      print('===================================================')\n",
    "    elif \"HumanMessage\" in str(reply):\n",
    "      reply = str(reply).split(\"content='\")[1].split(\", additional_k\")[0]\n",
    "  cs.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "9SYuvsksl4Yi"
   },
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"messages\": [\n",
    "        HumanMessage('smiles: O=C(O)[C@@](NN)(Cc1cc(O)c(O)cc1)C, protein:DRD2')\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_IzGB5Sn5K6q",
    "outputId": "b89143ce-0952-4a80-c6ef-a8472dbe90b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_smiles:  O=C(O)[C@@](NN)(Cc1cc(O)c(O)cc1)C\n",
      "query_protein: DRD2\n",
      "The docking calculation results indicate that the molecule represented by the SMILES string O=C(O)[C\n",
      "@@](NN)(Cc1cc(O)c(O)cc1)C was docked into the DRD2 protein. The specific conformer and pose that res\n",
      "ulted in the lowest electronic binding energy were identified as conformer 8 and pose 0, respectivel\n",
      "y. The binding energy for this pose was calculated to be -12.034 kcal/mol. This negative value sugge\n",
      "sts a favorable interaction between the molecule and the DRD2 protein, indicating that the molecule \n",
      "may be a potential ligand or inhibitor that could bind effectively to the DRD2 protein. The docking \n",
      "results provide valuable insights into the potential binding affinity and interaction of the molecul\n",
      "e with the target protein, which can be further investigated for drug discovery and development purp\n",
      "oses.' additional_kwargs={} response_metadata={} id='run--f33efdb2-9d6c-4725-ad60-8b34fc767f20-0'\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "cs = []\n",
    "for c in graph.stream(input): #, stream_mode='updates'):\n",
    "  m = re.findall(r'[a-z]+\\_node', str(c))\n",
    "  if len(m) != 0:\n",
    "    reply = c[str(m[0])]['messages']\n",
    "    if 'assistant' in str(reply):\n",
    "      reply = str(reply).split(\"<|assistant|>\")[-1].split('#')[0].strip()\n",
    "      print_short(reply)\n",
    "      print('===================================================')\n",
    "    elif \"HumanMessage\" in str(reply):\n",
    "      reply = str(reply).split(\"content='\")[1].split(\", additional_k\")[0]\n",
    "  cs.append(c)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
